# Связь ценности ПО и тестирования

Написание теста на первый взгляд имеет очевидную цель - верификацию наблюдаемого поведения. На самом деле, цель зависит
от формы, принятой за целевую в тестировании. Так, например unit тесты отличаются достаточно сильной привязанностью к
портам системы, т. к. исполняют её в сильно ограниченном окружении, и, таким образом верифицируют не столько поведение,
сколько саму возможность (и простоту) такого использования.

Если подняться выше, и добавить больше элементов в проверочные кейсы, то получится уже менее открытая система, больше
напоминающая черный ящик, где соотношение верификации расширяемости и корректности будет в пользу последнего.
Интеграционные тесты характеризуются данным качеством.

Крайней точкой же в данном вопросе являются тесты, полностью использующие целевую среду выполнения и средства
взаимодействия с программой. Таким образом полностью или в большинстве своём закрываясь от структуры ПО, полностью
концентрируясь на его поведении.

Здесь важно проследить связь между структурной/поведенческой ценностями ПО и степенью их верификации через
подпрограммы.

## Тестирование структурной ценности

Чем сильнее связь со структурной ценностью, тем меньше сопротивляемости к рефакторингу образуется в итоге.

Опираясь на структуру, тесты вынуждают её быть простой в повторном использовании (т. е. тестируемой). Что приводит к
расширяемым функциям, классам, модулям (т. е. объектам тестирования).

Наличие расширяемости можно использовать в целях построения изолированной среды выполнения, таким образом
существенно ускоряя выполнение проверок. Это неизбежно приведет к пониженной защите от регресса, что можно частично
нивелировать упрощая не тестируемые компоненты. Такие элементы имеют особое название "Humble object", они
характеризуется своей конкретностью (тяжело поддаются расширению, т. е. тестированию) и простотой (содержат только
тривиальные элементы, в основном обычные делегирования внешним функциям)

## Тестирование поведенческой ценности

С другой стороны можно попытаться вовсе закрыться от внутренней структуры программы и сконцентрироваться исключительно
на наблюдаемом поведении. В таких условиях, сопротивляемость рефакторингу будет максимальной, ровно, как и протекция от
регрессии. К сожалению, минусом здесь является скорость выполнения тестов и относительная сложность их написания.

Вот некоторые из причин:

* Скорость выполнения
    * Наличие общего состояния делает в общем случае невозможным параллельное (или выборочное)
      выполнение тестов. Порядок и содержание всегда задаётся строгим образом.
    * Прямое использование всех или большинства компонентов системы, естественным образом
      увеличивает время выполнения проверок, что может негативно сказаться на частоте запусков, а в некоторых
      случаях и в прямом игнорировании тестов.
* Сложность написания
    * При визуальной верификации требуется приводить систему к изначальному
      состоянию, т. е. поведение компонентов в таком случае должно быть воспроизводимым, что не всегда так. Примером
      может служить rand функции или неизменяемые данные (история изменений) Реализация предикатов на корректность
      поведения может отличаться от случая к случаю.
    * В случаях визуального тестирования, особого внимания заслуживает анимации, требующие отдельного контроля, так как
      может негативно повлиять на точность результатов тестирования. Также влиять могут и особенности отрисовки
      элементов, на которые может влиять аппаратное обеспечение компьютера.
    * Корректность исполнения внешних эффектов программы не всегда просто проверить. Например, обращения к внешним
      системам зачастую сложно проверить. Ввиду отсутствия прямого контроля, поведение таких систем недетерминировано и
      как вариант может занимать часы, а то и дни на выполнение.

Выбор сильно зависит от специфики, требований и общих условий проекта. Так, разработчики относительно тривиального
интернет магазина могут выбрать для себя больший уклон в верификацию наблюдаемого поведения, иначе тесты на меньшее
могут оказаться бесполезными и только усложнять общее решение.

Разработчики библиотеки низкого уровня (например lodash), наоборот, неизбежно будут верифицировать и часть структуры.
Хотя с их точки зрения, это и будет частью наблюдаемого поведения.

На проектах средней сложности могут подойти соотношения тестов разных видов. Сквозные сценарии и наиболее вероятные
альтернативные могут проверяться тестами более высокого порядка. Все остальное возможно верифицировать уже на более
низком уровне. Возьмем в пример процесс регистрации пользователя. Можно покрыть позитивный сценарий визуальным
тестированием, но вот уже разные сценарии валидации сложности пароля уже проверять отдельно, в более изолированном
окружении.

Таким образом, с одной стороны будет получена защита от регресса для позитивного сценария, и в то же время
будет протестировано гораздо большее количество сценариев функции валидации пароля. Возможности такой сегрегации, с
сохранением основных качеств тестирования на должном уровне, может быть достигнуто только при наличии расширяемой
архитектуры.

# Привет, мир

В качестве отправной точки возьмем экстремум, а именно тесты, ни коим образом не зависящие от структуры, целиком и
полностью проверяющие исключительно наблюдаемое поведение.

Как следствие, они не требуют ничего от программы, воспринимая её как один, неделимый компонент, монолит:

![img.png](img.png)

Зеленным цветом будут выделяться тестируемые элементы системы (в данном случае сама система является тестируемой).

Как показывалось ранее, такие тесты хоть и обладают наивысшей защитой от регресса и сопротивляемостью рефакторингу, их
чрезвычайно тяжело поддерживать и выполнять. В итоге это может вылиться только в большие затраты по времени (и по
бюджету как следствие). Тесты станут просто невыгодными и здравой альтернативой будет стратегия внесения изменений через
расширение, "ручные" проверки или частичное покрытие.

## Оптимизация

Сам собой встает вопрос, можем ли мы каким-либо образом изменить структуру так, чтобы наличие тестов стало оправданным?
Для этого нам нужно сделать их более поддерживаемыми и быстрыми в исполнении.

# Внешние источники данных

Первым и одним из самых очевидных элементов системы, тяжело поддающихся тестированию, являются запросы к внешним
источникам данных. Это необязательно запросы к "удаленному серверу" в классическом понимании. Здесь подойдут
любые функции которые обладают двумя свойствами:

* Зависимость от скрытых аргументов - например от базы данных, состояние которой может отличаться от времени запуска
  тестов.
* Наличие внешних эффектов - запись в local storage значения может повлиять на работу системы, тем самым усложняя
  процесс верификации поведения.

Выделим такие функции во внешний компонент системы и назовем их "Repositories"

![img_1.png](img_1.png)

Данный блок очевидно не является окрашенным, т. к. намеренно не покрывается автоматизированными проверками. Это также
обязывает его быть скромным.

# Заключение

Приведенные выше техники не являются откровением. Они достаточно известны и часто встречаются в литературе, однако, их
редко используют по причинам либо непонимания решаемых целей и задач, либо при отсутствии успехов их согласования с
заказчиком (согласование работ по техническому долгу и/или написание тестов). Оба фактора связаны. Относясь к паттернам
как к "брэндам", используя их по форме, а не по содержанию, программист рискует только ускорить процесс гниения проекта.

Одной из основных ролей инженера заключается в понимании просто факта: с каждым реализованным требованием, с каждым
исправленным дефектом сложность системы неуклонно растет, выражаясь в возрастающем времени выполнения задач.
Следовательно, стоимость проекта увеличивается, что не всегда можно сказать про бюджет.

Поэтому чрезвычайно важно контролировать данный показатель, путем постоянной корректировки структуры в направление
упрощения поддержки и развития ПО. Это делается не один раз, не раз в неделю, а непрерывно на протяжении всего цикла
разработки. Достичь этого нельзя не имея при этом качественных тестов. Они в свою очередь, требуют использования
подходящих структурных парадигм и паттернов, таким образом у последних появляется четкая, измеряемая причина для
существования - деньги.

Что более важно, эта причина понятна не только разработчикам, но и менеджерам, заказчикам и руководителям, тем, перед
кем и требуется чаще всего обосновывать данные работы. Нам этого не говорят напрямую, но от нас ожидают умения сказать
"нет", предупредить риски, обеспечить расширяемость и поддерживаемость системы на всем периоде её существования.

### Заметки

SRP - разделение тестов на представление и все остальное (пример с функцией валидации пароля и обрисовкой ошибки зеленым
цветом)
OCP - расширяемость тестируемых элементов проявляется через возможность их тестирования
LSP - моки должны быть подтипами основных репозиториев
ISP - ограниченное кол-во зависимостей упрощает повторное использование (а значит и тестирование) компонент
DIP - как основной метод разделения компонентов, при котором в рамках тестирования возможно использовать моки